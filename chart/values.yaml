# When set to true the chart will use values defined with production: sections over development: sections
# It was created for swapping between running the chart on a development kubernetes cluster with minimal
# resources vs a production one.
is_production: false

# When scaling the _helpers.tpl function that is used for scaling out nodes will do a calculation based on this label
# Basically it will count the total number of nodes that have this label
# WARNING: If none of the nodes have this logstash replicas will get SET to 0
node_count_label:
  key: cnaps.io/node-type
  value: Tier-1

image:
  repository: ghcr.io/idaholab/malcolm
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion found in Chart.yml.
  # Should only need to override these if something is awry with version supplied in Chart.yaml file.
  dirinit_tag: ""
  dashboards_tag: ""
  opensearch_tag: ""
  upload_tag: ""
  pcap_monitor_tag: ""
  arkime_tag: ""
  api_tag: ""
  zeek_container_override: ""
  suricata_tag: ""
  dashboards_helper_tag: ""
  file_monitor_tag: ""
  filebeat_tag: ""
  logstash_tag: ""
  redis_tag: ""
  postgresql_tag: ""
  netbox_tag: ""
  htadmin_tag: ""
  pcap_capture_tag: ""
  freq_tag: ""
  nginx_tag: ""

auth:
  username: vagrant
  # Generated with the openssl passwd -1 <your password>
  openssl_password: "$1$9akV05vU$JHFoK3C2dDquTFAMoz14x/"
  # Generated with  htpasswd -bnB <your username> <your password>
  htpass_cred: "vagrant:$2y$05$kaHZ2j2VDDQCBf9bEk1gMuJAPRs4q4rolPRbq3zXUb7j2JyGuc50a"
  arkime_password: vagrant

opensearch:
  enabled: true
  singleNode: true
  replicas: 3
  url: http://opensearch:9200
  dashboards_url: http://dashboards:5601/dashboards
  development:
    java_memory: -Xmx4g -Xms4g -Xss256k -XX
  production:
    java_memory: -Xmx32g -Xms32g -Xss256k -XX

external_elasticsearch:
  enabled: false
  # Internal url or clusterIP service and supports https or http urls for elasticsearch
  url: https://dataplane-ek-es-http.dataplane-ek.svc:9200
  username: "elastic"
  password: ""
  # Secret must be in following format if using elastic_secret_name:
  # apiVersion: v1
  #  data:
  #    elastic: passwordbase64encoded
  # kind: Secret
  # type: Opaque
  # metadata:
  #   name: somename
  #   namespace: somenamespace
  elastic_secret_name: "dataplane-ek-es-elastic-user"
  elastic_secret_namespace: "dataplane-ek"

  # Copy of the elastic certificate from elasticsearch namespace
  elastic_cert_name: "dataplane-ek-es-http-certs-public"
  elastic_cert_namespace: "dataplane-ek"

  # Only supports http urls for Kibana.
  dashboards_url: "http://dataplane-ek-kb-http.dataplane-ek.svc.cluster.local:5601"
  # Used for the Malcolm landing page and is only used if using a external_elasticsearch
  external_dashboards_url: https://dataplane-kibana.vp.bigbang.dev

# Shared environment varibles for both Elasticsearch and Opensearch
siem_env:
  # OpenSearch index patterns and timestamp fields
  # Index pattern for network traffic logs written via Logstash (e.g., Zeek logs, Suricata alerts)
  logstash_override:
    # When enabled the elasticsearch / opensarch logstash output plugin is modified to point to an ilm rollover alias
    # ILM policy and rollover_alias will need to be defined outside of this deployment for this to work as expected.
    enabled: false
    ilm_policy: nta
    # Must match arkime_network_index_pattern
    rollover_alias: malcolm_suricata_zeek

  malcolm_network_index_pattern: "arkime_sessions3-*"
  # Default time field to use for network traffic logs in Logstash and Dashboards
  malcolm_network_index_time_field: "firstPacket"
  # Suffix used to create index to which network traffic logs are written
  #   (supports Ruby strftime strings in %{}; e.g.,
  #    hourly: %{%y%m%dh%H}, twice daily: %{%P%y%m%d}, daily: %{%y%m%d}, weekly: %{%yw%U}, monthly: %{%ym%m})
  malcolm_network_index_suffix: "%{%y%m%d}"
  # Index pattern for other logs written via Logstash (e.g., nginx, beats, fluent-bit, etc.)
  malcolm_other_index_pattern: "malcolm_beats_*"
  # Default time field to use for other logs in Logstash and Dashboards
  malcolm_other_index_time_field: "@timestamp"
  # Suffix used to create index to which other logs are written (supports Ruby strftime strings in %{})
  malcolm_other_index_suffix: "%{%y%m%d}"
  # Index pattern used specifically by Arkime (will probably match MALCOLM_NETWORK_INDEX_PATTERN, should probably be arkime_sessions3-*)
  arkime_network_index_pattern: "arkime_sessions3-*"
  # Default time field used by for sessions in Arkime viewer
  arkime_network_index_time_field: "firstPacket"


logstash:
  # Note the number of logstash instances will be based on the number of nodes in your kubernetes cluster.
  development:
    java_memory: -Xmx1g -Xms1g -Xss1536k -XX
    #See https://www.elastic.co/guide/en/logstash/current/tuning-logstash.html for details on these parameters.
    workers: 6
    batch_delay: 50
    batch_size: 75
  production:
    java_memory: -Xmx16g -Xms16g -Xss1536k -XX
    workers: 18
    batch_delay: 50
    batch_size: 75

netbox:
  enabled: true
  # Set this this value to your reverse proxy url or leave it blank
  csrf_trusted_origins: https://malcolm.vp.bigbang.dev
  netbox_default_site: Cyberville
  netbox_auto_populate: false
  netbox_cache_size: "1000"
  netbox_cache_ttl: "30"

  database:
   host: netbox-postgres
   name: netbox
   password: "ChangeMe!"
   # Set true if using custom database for netbox
   is_custom: false
   # Create extra secrets for custom database, empty attributes will be set to password key.
   # The password will be same for all empty attributes.
   extra_secrets: [{}]
    # Example
    # - postgresql-secret:
    #     username: netbox
    #     password: ""
    # - pgpool-secret:
    #     adminUsername: netbox-pgpool
    #     adminPassword: ""

storage:
  # This helm chart requires a storage provisioner class it defaults to local-path provisioner
  # If your kuberenetes cluster has a different storage provisioner please ensure you change this name.
  # https://github.com/rancher/local-path-provisioner
  development:
    pcap_claim:
      # The size of the claim
      size: 25Gi
      # The kubernetes storage class name
      className: local-path
    zeek_claim:
      size: 25Gi
      className: local-path
    suricata_claim:
      size: 25Gi
      className: local-path
    config_claim:
      size: 25Gi
      className: local-path
    runtime_logs_claim:
      size: 25Gi
      className: local-path
    opensearch_claim:
      size: 25Gi
      className: local-path
    opensearch_backup_claim:
      size: 25Gi
      className: local-path
    netbox_postgres_claim:
      size: 15Gi
      className: local-path
  production:
    pcap_claim:
      size: 100Gi
      className: local-path
    zeek_claim:
      size: 50Gi
      className: local-path
    suricata_claim:
      size: 50Gi
      className: local-path
    config_claim:
      size: 25Gi
      className: local-path
    runtime_logs_claim:
      size: 25Gi
      className: local-path
    opensearch_claim:
      size: 25Gi
      className: local-path
    opensearch_backup_claim:
      size: 25Gi
      className: local-path
    netbox_postgres_claim:
      size: 15Gi
      className: local-path

ingress:
  # Enable this if deploying in RKE2 environment with the default nginx ingress controller
  enabled: true

istio:
  # Enable this if deploying in Kuberenetes environment leveraging istio service mesh
  # Additionally, it is recommended to turn off tls everywhere when this is set to true and let tls handle all things tls :).
  enabled: false
  gateway: istio-system/tenant
  virtualservicename: malcolm
  domain: vp.bigbang.dev

# Suricata live is enabled by default and will listen pcap_iface
# Defined under pcap_capture_env
# If you disable it, you will still be able to upload pcaps using the malcolm offline upload of pcaps functionality.
#https://docs.suricata.io/en/suricata-6.0.0/performance/tuning-considerations.html#af-packet AF_PACKET_RING_SIZE
suricata_live:
  enabled: true
  suricata_stats_enabled: true
  suricata_log_path: /opt/suricata/logs
  # Suricata live is a Daemonset but it will only schedule on kubernetes nodes that has following label
  nodeSelector:
    cnaps.io/suricata-capture: "true"

  development:
    af_packet_iface_threads: 2
    af_packet_ring_size: 2048
    max_pending_packets: 1024
    stream_memcap: "64mb"
    host_memcap: "32mb"
    defrag_memcap: "32mb"
    ftp_memcap: "64mb"
    stream_reassembly_memcap: "256mb"
    flow_memcap: "128mb"
    eve_threaded: "true"
    eve_rotate_interval: "1h"
    # Used if is production is set to true
  production:
    af_packet_iface_threads: 32
    # Default is calculated threads * max-pending-packets (Default of max-pending-packets is 1024)
    # This calculation was made with the assumtion that max-pending-packets is set to 1024
    af_packet_ring_size: 131072
    max_pending_packets: 8192
    stream_memcap: "16gb"
    host_memcap: "32mb"
    defrag_memcap: "16gb"
    ftp_memcap: "4gb"
    stream_reassembly_memcap: "16gb"
    flow_memcap: "16gb"
    eve_threaded: "true"
    eve_rotate_interval: "1h"

dashboards_helper_env:
  opensearch_index_size_prune_limit: 0
  opensearch_index_size_prune_name_sort: false

suricata_offline:
  development:
    suricata_auto_analyze_pcap_threads: 1
  production:
    suricata_auto_analyze_pcap_threads: 3

# Zeek live is enabled by default and will listen pcap_iface
# Defined under pcap_capture_env
# If you disable it, you will still be able to upload pcaps using the malcolm offline upload of pcaps functionality.
zeek_live:
  enabled: true
  zeek_disable_stats: ""
  zeek_log_path: /opt/zeek/logs
  # Zeek live is a Daemonset but it will only schedule on kubernetes nodes that has following label
  nodeSelector:
    cnaps.io/zeek-capture: "true"

  development:
    zeek_lb_procs: "1"
    worker_lb_procs: "1"
    zeek_lb_method: "custom"
    zeek_af_packet_buffer_size: "67108864"
    zeek_pin_cpus_worker_1: "1"
  production:
    zeek_lb_procs: "24"
    worker_lb_procs: "24"
    zeek_lb_method: "custom"
    zeek_af_packet_buffer_size: "134217728"
    zeek_pin_cpus_worker_1: "1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24"


# Only affects the zeek offline deployment
zeek_offline:
  # The number of Zeek processes for analyzing uploaded PCAP files allowed
  #   to run concurrently
  development:
    zeek_auto_analyze_pcap_threads: 1
  production:
    zeek_auto_analyze_pcap_threads: 3


# Affects all zeek deployment live and offline
zeek_env:
  #Set to none, all or interesting.
  # `none`: no file extraction
  # `interesting`: extraction of files with mime types of common attack vectors
  # `notcommtxt`: extraction of all files except common plain text files
  # `mapped`: extraction of files with recognized mime types
  # `known`: extraction of files for which any mime type can be determined
  # `all`: extract all files
  extract_mode: interesting
  extracted_file_enable_capa: true
  extracted_file_enable_clamav: true
  extracted_file_enable_yara: true
  extracted_file_http_server_enable: true
  extracted_file_http_server_recursive: true
  extracted_file_preservation: quarantined
  development:
    capa_max_requests: 4
    clamd_max_requests: 8
    yara_max_requests: 8
    extracted_file_max_bytes: "134217728"
    extracted_file_min_bytes: "64"
  production:
    capa_max_requests: 8
    clamd_max_requests: 16
    yara_max_requests: 16
    extracted_file_max_bytes: "134217728"
    extracted_file_min_bytes: "64"

# Variables apply to both offline and live version of arkime
arkime_env:
  arkime_debug_level: "0"
  development:
    free_space_g: "10%"
    rotate_index: daily
    # These variables manage setting for Arkime's ILM/ISM features (https://arkime.com/faq#ilm)
    # Whether or not Arkime should perform index management
    index_management_enabled: "false"
    # Time in hours/days before moving to warm and force merge (number followed by h or d)
    index_management_optimization_period: "30d"
    # Time in hours/days before deleting index (number followed by h or d)
    index_management_retention_time: "90d"
    # Number of replicas for older sessions indices
    index_management_older_session_replicas: "0"
    # Number of weeks of history to retain
    index_management_history_retention_weeks: "13"
    # Number of segments to optimize sessions for
    index_management_segments: "1"
    # Whether or not Arkime should use a hot/warm design (storing non-session data in a warm index)
    index_management_hot_warm_enabled: "false"
  production:
    free_space_g: "20%"
    rotate_index: hourly
    index_management_enabled: "false"
    index_management_optimization_period: "30d"
    index_management_retention_time: "90d"
    index_management_older_session_replicas: "0"
    index_management_history_retention_weeks: "13"
    index_management_segments: "1"
    index_management_hot_warm_enabled: "false"

arkime_live:
  enabled: true
  pcap_hostpath: "/zpool/nta-pcap"
  development:
    arkime_compression_type: none
    arkime_compression_level: "0"
    arkime_db_bulk_size: "4000000"
    arkime_max_packets_in_queue: "300000"
    arkime_packet_threads: "2"
    arkime_pcap_write_size: "2560000"
    arkime_tpacketv3_num_threads: "2"
    arkime_tpacketv3_block_size: "8388608"
  production:
    arkime_compression_type: none
    arkime_compression_level: "3"
    arkime_db_bulk_size: "4000000"
    arkime_max_packets_in_queue: "300000"
    arkime_packet_threads: "16"
    arkime_pcap_write_size: "2560000"
    arkime_tpacketv3_num_threads: "16"
    arkime_tpacketv3_block_size: "8388608"

  # Arkime live is a Daemonset but it will only schedule on kubernetes nodes that has following label
  nodeSelector:
    cnaps.io/arkime-capture: "true"

pcap_live:
  enabled: false

  # Pcap live is a Daemonset but it will only schedule on kubernetes nodes that has following label
  nodeSelector:
    cnaps.io/pcap-capture: "true"

# Sets environment variables across multiple applications within Malcolm (IE: pcap capture, zeek and suricata)
# pcap_iface can be comma separate values.
pcap_capture_env:
  pcap_iface: ens192
  pcap_filter: ""
  # NOTE Net Sniff and tcpdump cannot be both true. Only one or the other can be running at a time.
  net_sniff: false
  tcpdump: true
  pcap_rotate_megabytes: 4096
  pcap_rotate_minutes: 10
  home_net: "192.168.0.0/16,10.0.0.0/8,172.16.0.0/12"
  pcap_iface_tweak: true


# Shared settings across all live capture type things (IE: Zeek live, Suricata live, and Pcap capture)
live_capture:
  tolerations:
  - key: node-role.kubernetes.io/control-plane
    operator: Exists
    effect: NoSchedule
  - key: node-role.kubernetes.io/master
    operator: Exists
    effect: NoSchedule
  - key: "cnaps.io/node-taint"
    operator: "Equal"
    value: "noncore"
    effect: "NoSchedule"

# Filebeat capture
filebeat:
  filebeat_clean_inactive: 180m
  filebeat_close_inactive: 120s
  filebeat_close_inactive_live: 90m
  filebeat_ignore_older: 120m
  filebeat_scan_frequency: 10s
  # The age (in minutes) at which already-processed log files containing network traffic metadata should
  #   be pruned from the filesystem
  log_cleanup_minutes: "60"
  # The age (in minutes) at which the compressed archives containing already-processed log files should
  #   be pruned from the filesystem
  zip_cleanup_minutes: "90"


# Default affinity ensures that the filebeat Daemonset is applied with anything that also has suricata or zeek live capture running on it.
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
      - matchExpressions:
        - key: cnaps.io/suricata-capture
          operator: In
          values:
          - "true"
        - key: cnaps.io/zeek-capture
          operator: In
          values:
          - "true"

# Sets GID and UID for each container
process_env:
  pgid: 1000
  puid: 1000

# Only set to true if you intend on mounting these specific folders yourself using a kustomize overlay.
rule_mount_override:
  enabled: false

zeek_chart_overrides:
  serviceAccountName: ""
  sideCars: []
  volumes: []
  volumeMounts: []
  live_volumes: []
  live_volumeMounts: []

suricata_chart_overrides:
  serviceAccountName: ""
  sideCars: []
  volumes: []
  volumeMounts: []
  live_volumes: []
  live_volumeMounts: []